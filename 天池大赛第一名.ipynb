{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#将数据分为3个数据集 利用滑窗法\n",
    "#将2016年1月1日到4月13日的数据提取特征，利用4月14日的到5月14日的作为测试集\n",
    "#将2月1日到5月14日的作为数据集提取特征，利用5月15日6月15日的作为测试集\n",
    "#将3月15日到6月30日作为数据集提取特征，再测试7月1日到7月31日的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160528.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160613.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         4663    11002.0        150:20       1.0     20160528.0   \n",
       "2  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "3  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "4  1439408         2632     8591.0          20:1       0.0     20160613.0   \n",
       "\n",
       "         Date  \n",
       "0  20160217.0  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1 提取用户特征\n",
    "    距离\n",
    "    用户的平均距离，用户的最小距离，用户的最大距离\n",
    "    使用优惠券买的物品数，买的总数，收到的优惠券数\n",
    "    使用优惠券买的/总共收到的优惠券\n",
    "\"\"\"\n",
    "#利用pandas读取csv个格式的数据,header=None表示原文件没有索引\n",
    "#原文件中总共有1754884个记录,header=0，表明第0行代表列名\n",
    "off_train = pd.read_csv('C:\\data\\O2O_tianchi\\ccf_offline_stage1_train.csv',header=0)\n",
    "# print(off_train)\n",
    "off_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>distance</th>\n",
       "      <th>date_received</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160528.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160613.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  coupon_id discount_rate  distance  date_received  \\\n",
       "0  1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1  1439408         4663    11002.0        150:20       1.0     20160528.0   \n",
       "2  1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "3  1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "4  1439408         2632     8591.0          20:1       0.0     20160613.0   \n",
       "\n",
       "         date  \n",
       "0  20160217.0  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_train.columns=['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']\n",
    "off_test = pd.read_csv(\"C:\\data\\O2O_tianchi\\ccf_offline_stage1_test_revised.csv\",header=0)\n",
    "off_test.head()\n",
    "off_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1754884 entries, 0 to 1754883\n",
      "Data columns (total 7 columns):\n",
      "user_id          int64\n",
      "merchant_id      int64\n",
      "coupon_id        float64\n",
      "discount_rate    object\n",
      "distance         float64\n",
      "date_received    float64\n",
      "date             float64\n",
      "dtypes: float64(4), int64(2), object(1)\n",
      "memory usage: 93.7+ MB\n"
     ]
    }
   ],
   "source": [
    "off_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>action</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>date_received</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13740231</td>\n",
       "      <td>18907</td>\n",
       "      <td>2</td>\n",
       "      <td>100017492</td>\n",
       "      <td>500:50</td>\n",
       "      <td>20160513.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13740231</td>\n",
       "      <td>34805</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14336199</td>\n",
       "      <td>18907</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160618.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14336199</td>\n",
       "      <td>18907</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160618.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14336199</td>\n",
       "      <td>18907</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160618.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  merchant_id  action  coupon_id discount_rate  date_received  \\\n",
       "0  13740231        18907       2  100017492        500:50     20160513.0   \n",
       "1  13740231        34805       1        NaN           NaN            NaN   \n",
       "2  14336199        18907       0        NaN           NaN            NaN   \n",
       "3  14336199        18907       0        NaN           NaN            NaN   \n",
       "4  14336199        18907       0        NaN           NaN            NaN   \n",
       "\n",
       "         date  \n",
       "0         NaN  \n",
       "1  20160321.0  \n",
       "2  20160618.0  \n",
       "3  20160618.0  \n",
       "4  20160618.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#线上数据\n",
    "on_train = pd.read_csv(\"C:\\data\\O2O_tianchi\\ccf_online_stage1_train.csv\",header=0)\n",
    "on_train.columns = ['user_id','merchant_id','action','coupon_id','discount_rate','date_received','date']\n",
    "on_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>distance</th>\n",
       "      <th>date_received</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>10:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  merchant_id  coupon_id discount_rate  distance  date_received  \\\n",
       "0   1439408         2632        NaN           NaN       0.0            NaN   \n",
       "2   1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "3   1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "8   2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "16  2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
       "\n",
       "        date  \n",
       "0   20160217  \n",
       "2          0  \n",
       "3          0  \n",
       "8          0  \n",
       "16         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使数据集等于test集\n",
    "dataset3 = off_test\n",
    "dataset3.head()\n",
    "# #数据集3的特征为 取 线上数据中领券和用券日期大于3月15日和小于6月30日的\n",
    "off_train['date']=off_train['date'].fillna(0)\n",
    "off_train['date']=off_train['date'].astype('int')\n",
    "off_train.head()\n",
    "feature3 = off_train[((off_train['date'] >= 20160315)&(off_train.date<=20160630))|((off_train['date']==0)&(off_train['date_received']>=20160315)&(off_train['date_received']<=20160630))]\n",
    "feature3.head()\n",
    "# type(off_train['date']Date\n",
    "#提取数据集2的测试集\n",
    "dataset2 = off_train[(off_train['date_received']>=20160515)&(off_train['date_received']<=20160615)]\n",
    "dataset2.head()\n",
    "#在2月1日到5月14日之间使用了券,只要领取时间在2月1日到5月14日之间,并包括没有数据中没有领取券的\n",
    "feature2 = off_train[(off_train['date']>=20160201)&(off_train['date']<=20160514)|((off_train['date']==0)&(off_train['date_received']>=20160201)&(off_train['date_received']<=20160514))]\n",
    "feature2.head()\n",
    "#同理可得\n",
    "dataset1 = off_train[(off_train['date_received']>=201604014)&(201604014<=20160514)]\n",
    "feature1 = off_train[(off_train['date']>=20160101)&(off_train.date<=20160413)|((off_train['date']==0)&(off_train['date_received']>=20160101)&(off_train['date_received']<=20160413))]\n",
    "feature1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "这里用到的特征有\n",
    "    用户领取的所有优惠券数目\n",
    "    ◦用户领取的特定优惠券数目\n",
    "    ◦用户此次之后/前领取的所有优惠券数目\n",
    "    ◦用户此次之后/前领取的特定优惠券数目\n",
    "    ◦用户上/下一次领取的时间间隔\n",
    "    ◦用户领取特定商家的优惠券数目\n",
    "    ◦用户领取的不同商家数目\n",
    "    ◦用户当天领取的优惠券数目\n",
    "    ◦用户当天领取的特定优惠券数目\n",
    "    ◦用户领取的所有优惠券种类数目\n",
    "    ◦商家被领取的优惠券数目\n",
    "    ◦商家被领取的特定优惠券数目\n",
    "    ◦商家被多少不同用户领取的数目\n",
    "    ◦商家发行的所有优惠券种类数目\n",
    "这些特征都是在预测集中被提取的\n",
    "\"\"\"\n",
    "#对于测试集3，提取用户的Id\n",
    "dataset3.head()\n",
    "t = dataset3[['User_id']].copy()\n",
    "t.head()\n",
    "# #相当于给原有数据加上一列，这个月用户收取的所有优惠券数目，并初始化为1\n",
    "t['this_month_user_receive_all_coupon_count']=1\n",
    "t.head()\n",
    "\n",
    "#将t按照用户id进行分组，然后统计所有用户收取的优惠券数目,并初始化一个索引值\n",
    "t = t.groupby('User_id').agg('sum').reset_index()\n",
    "t.head()\n",
    "#提取数据集3的优惠券Id和用户Id\n",
    "t1 = dataset3[['User_id','Coupon_id']].copy()\n",
    "#提取这个月用户收到的相同的优惠券的数量\n",
    "t1['this_month_user_receive_same_coupn_count'] = 1\n",
    "t1 = t1.groupby(['User_id','Coupon_id']).agg('sum').reset_index()\n",
    "\n",
    "#提取数据集3的用户id，优惠券id以及优惠券接收的时间\n",
    "t2 = dataset3[['User_id','Coupon_id','Date_received']].copy()\n",
    "#将数据转换为str类型\n",
    "t2['Date_received'] = t2['Date_received'].astype('str')\n",
    "#如果出现相同的用户接收相同的优惠券在接收时间上用‘：’连接上第n次接受优惠券的时间\n",
    "t2 = t2.groupby(['User_id','Coupon_id'])['Date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "# t2 = t2.groupby(['User_id','Coupon_id']).agg(lambda x:':'.join(x)).reset_index()\n",
    "t2 = t2.groupby(['User_id','Coupon_id'])['Date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "t2.head(30)\n",
    "# #将接收时间的一组按着':'分开，这样就可以计算接受了优惠券的数量,apply是合并\n",
    "t2['receive_number'] = t2['Date_received'].apply(lambda s:len(s.split(':')))\n",
    "t2 = t2[t2['receive_number'] > 1]\n",
    "t2.head()\n",
    "\n",
    "#最大接受的日期\n",
    "t2['max_date_received'] = t2['Date_received'].apply(lambda s:max([int (d) for d in s.split(':')]))\n",
    "#最小的接收日期\n",
    "t2['min_date_received'] = t2['Date_received'].apply(lambda s:min([int (d) for d in s.split(':')]))\n",
    "t2.head()\n",
    "t2 = t2[['User_id','Coupon_id','max_date_received','min_date_received']]\n",
    "t3 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "\n",
    "#将两表融合只保留左表数据,这样得到的表，相当于保留了最近接收时间和最远接受时间\n",
    "t3 = pd.merge(t3,t2,on=['User_id','Coupon_id'],how='left')\n",
    "#这个优惠券最近接受时间\n",
    "t3['this_month_user_receive_same_coupon_lastone']= t3['max_date_received']-t3['Date_received'].astype(int)\n",
    "#这个优惠券最远接受时间\n",
    "t3['this_month_user_receive_same_coupon_firstone'] = t3['Date_received'].astype(int)-t3['min_date_received']\n",
    "\n",
    "def is_firstlastone(x):\n",
    "    if x==0:\n",
    "        return 1\n",
    "    elif x>0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1 #表明这个优惠券只接受了一次\n",
    "t3['this_month_user_receive_same_coupon_lastone'] = t3['this_month_user_receive_same_coupon_lastone'].apply(is_firstlastone)\n",
    "t3['this_month_user_receive_same_coupon_firstone'] = t3['this_month_user_receive_same_coupon_firstone'].apply(is_firstlastone)\n",
    "t3 = t3[['User_id','Coupon_id','Date_received','this_month_user_receive_same_coupon_lastone','this_month_user_receive_same_coupon_firstone']]\n",
    "\n",
    "#提取第四个特征,一个用户所接收到的所有优惠券的数量\n",
    "t4 = dataset3[['User_id','Date_received']]\n",
    "t4.loc['this_day_receive_all_coupon_count'] = 1\n",
    "t4 = t4.groupby(['User_id','Date_received']).agg('sum').reset_index()\n",
    "#提取第五个特征,一个用户不同时间所接收到不同优惠券的数量\n",
    "t5 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "t5['this_day_user_receive_same_coupon_count'] = 1\n",
    "t5 = t5.groupby(['User_id','Coupon_id','Date_received']).agg('sum').reset_index()\n",
    "#一个用户不同优惠券 的接受时间\n",
    "t6 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "t6.Date_received = t6.Date_received.astype('str')\n",
    "t6 = t6.groupby(['User_id','Coupon_id'])['Date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "#重命名inplace代表深拷贝\n",
    "t6.rename(columns={'Date_received':'dates'},inplace = True)\n",
    "\n",
    "def get_day_gap_before(s):\n",
    "    Date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        #将时间差转化为天数\n",
    "        this_gap = (dt.date(int(Date_received[0:4]),int(Date_received[4:6]),int(Date_received[6:8]))-dt.date(int(d[0:4]),int(d[4:6]),int(d[6:8]))).days\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "def get_day_gap_after(s):\n",
    "    Date_received,dates = s.split('-')\n",
    "    dates = dates.split(':')\n",
    "    gaps = []\n",
    "    for d in dates:\n",
    "        this_gap = (dt.datetime(int(d[0:4]),int(d[4:6]),int(d[6:8]))-dt.datetime(int(Date_received[0:4]),int(Date_received[4:6]),int(Date_received[6:8]))).days\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t7 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "#将t6和t7融合\n",
    "t7 = pd.merge(t7,t6,on=['User_id','Coupon_id'],how='left')\n",
    "#注意这里所有的时间格式都已经是'str'格式\n",
    "t7['date_received_date'] = t7.Date_received.astype('str')+'-'+t7.dates\n",
    "#print(t7)\n",
    "t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before)\n",
    "t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)\n",
    "t7 = t7[['User_id','Coupon_id','Date_received','day_gap_before','day_gap_after']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将所有特征融合在一张表中\n",
    "other_feature3 = pd.merge(t1,t,on='User_id')\n",
    "other_feature3 = pd.merge(other_feature3,t3,on=['User_id','Coupon_id'])\n",
    "other_feature3 = pd.merge(other_feature3,t4,on=['User_id','Date_received'])\n",
    "other_feature3 = pd.merge(other_feature3,t5,on=['User_id','Coupon_id','Date_received'])\n",
    "other_feature3 = pd.merge(other_feature3,t7,on=['User_id','Coupon_id','Date_received'])\n",
    "other_feature3.to_csv('C:\\data\\other_feature3.csv',index=None)\n",
    "#print(other_feature3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取优惠券的相关特征\n",
    "\n",
    "def calc_discount_rate(s):\n",
    "    s = str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return float(s[0])\n",
    "    else:\n",
    "        return 1.0-float(s[1])/float(s[0])\n",
    "def get_discount_man(s):\n",
    "    s = str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s)==1:\n",
    "        return 'null'\n",
    "    else:\n",
    "        return int(s[0])\n",
    "def get_discount_jian(s):\n",
    "    s = str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return 'null'\n",
    "    else:\n",
    "        return int(s[1])\n",
    "\n",
    "def is_man_jian(s):\n",
    "    s = str(s)\n",
    "    s = s.split(':')\n",
    "    if len(s)==1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#显示时间是第几周\n",
    "dataset3['day_of_week'] = dataset3['Date_received'].astype('str').apply(lambda x:date(int(x[0:4]),int(x[4:6]),int(x[6:8])).weekday()+1)\n",
    "#显示时间是几月\n",
    "dataset3['day_of_month'] = dataset3['Date_received'].astype('str').apply(lambda x:int(x[6:8]))\n",
    "#显示时期和截止日之间的天数\n",
    "dataset3['days_distance'] = dataset3['Date_received'].astype('str').apply(lambda x:(date(int(x[0:4]),int(x[4:6]),int(x[6:8]))-date(2016,6,30)).days)\n",
    "#显示满了多少钱后开始减\n",
    "dataset3['discount_man'] = dataset3['Discount_rate'].apply(get_discount_man)\n",
    "#显示满减的减少的钱\n",
    "dataset3['discount_jian'] = dataset3['Discount_rate'].apply(get_discount_jian)\n",
    "#返回优惠券是否是满减券\n",
    "dataset3['is_man_jian'] = dataset3['Discount_rate'].apply(is_man_jian)\n",
    "#显示打折力度\n",
    "dataset3['Discount_rate'] = dataset3['Discount_rate'].apply(calc_discount_rate)\n",
    "d = dataset3[['Coupon_id']]\n",
    "d['coupon_count'] = 1\n",
    "#显示每一种优惠券的数量\n",
    "d = d.groupby('Coupon_id').agg('sum').reset_index()\n",
    "dataset3 = pd.merge(dataset3,d,on='Coupon_id',how='left')\n",
    "# print(dataset3)\n",
    "dataset3.to_csv('C:\\data\\coupon3_feature.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>distance</th>\n",
       "      <th>date_received</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160528.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160613.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160516.0</td>\n",
       "      <td>20160613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2029232</td>\n",
       "      <td>450</td>\n",
       "      <td>1532.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160530.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2029232</td>\n",
       "      <td>6459</td>\n",
       "      <td>12737.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160519.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  merchant_id  coupon_id discount_rate  distance  date_received  \\\n",
       "1   1439408         4663    11002.0        150:20       1.0     20160528.0   \n",
       "4   1439408         2632     8591.0          20:1       0.0     20160613.0   \n",
       "6   1439408         2632     8591.0          20:1       0.0     20160516.0   \n",
       "9   2029232          450     1532.0          30:5       0.0     20160530.0   \n",
       "10  2029232         6459    12737.0          20:1       0.0     20160519.0   \n",
       "\n",
       "        date  \n",
       "1          0  \n",
       "4          0  \n",
       "6   20160613  \n",
       "9          0  \n",
       "10         0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#对于数据集2\n",
    "dataset2['day_of_week'] = dataset2['date_received'].astype('str').apply(lambda x:date(int(x[0:4]),int(x[4:6]),int(x[6:8])).weekday()+1)\n",
    "dataset2['day_of_month'] = dataset2['date_received'].astype('str').apply(lambda x:int(x[6:8]))\n",
    "dataset2['days_distance'] = dataset2['date_received'].astype('str').apply(lambda x:(date(int(x[0:4]),int(x[4:6]),int(x[6:8]))-date(2016,5,14)).days)\n",
    "dataset2['discount_man'] = dataset2['discount_rate'].apply(get_discount_man)\n",
    "dataset2['discount_jian'] = dataset2['discount_rate'].apply(get_discount_jian)\n",
    "dataset2['is_man_jian'] = dataset2['discount_rate'].apply(is_man_jian)\n",
    "dataset2['discount_rate'] = dataset2['discount_rate'].apply(calc_discount_rate)\n",
    "d = dataset2[['coupon_id']]\n",
    "d['coupon_count'] = 1\n",
    "d = d.groupby('coupon_id').agg('sum').reset_index()\n",
    "dataset2 = pd.merge(dataset2,d,on='coupon_id',how='left')\n",
    "dataset2.to_csv('C:\\data\\coupon2_feature.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对于数据集1\n",
    "dataset1['day_of_week'] = dataset1['date_received'].apply(lambda x:date(int(x[0:4]),int(x[4:6]),int(x[6:8])).weekday()+1)\n",
    "dataset1['day_of_month'] = dataset1['date_received'].apply(lambda x:int(x[6:8]))\n",
    "dataset1['days_distance'] = dataset1['date_received'].apply(lambda x:(date(int(x[0:4]),int(x[4:6]),int(x[6:8]))-date(2016,4,13)).days)\n",
    "dataset1['discount_man'] = dataset1['discount_rate'].apply(get_discount_man)\n",
    "dataset1['discount_jian'] = dataset1['discount_rate'].apply(get_discount_jian)\n",
    "dataset1['is_man_jian'] = dataset1['discount_rate'].apply(is_man_jian)\n",
    "dataset1['discount_rate'] = dataset1['discount_rate'].apply(calc_discount_rate)\n",
    "d = dataset1[['coupon_id']]\n",
    "d['coupon_count'] = 1\n",
    "d = d.groupby('coupon_id').agg('sum').reset_index()\n",
    "dataset1 = pd.merge(dataset1,d,on='coupon_id',how='left')\n",
    "dataset1.to_csv('C:\\data\\coupon1_feature.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#提取商品的特征\n",
    "\n",
    "#对于数据集3\n",
    "merchant3 = feature3[['merchant_id','coupon_id','distance','date_received','date']]\n",
    "\n",
    "t = merchant3[['merchant_id']]\n",
    "#删除重复行数据\n",
    "t.drop_duplicates(inplace=True)\n",
    "merchant3.head()\n",
    "#显示卖出的商品\n",
    "t1 = merchant3[merchant3.date!=0][['merchant_id']]\n",
    "t1['total_sales'] = 1\n",
    "#显示每个商品的销售数量\n",
    "t1 = t1.groupby('merchant_id').agg('sum').reset_index()\n",
    "#显示使用了优惠券消费的商品，正样本\n",
    "t2 = merchant3[(merchant3.date!=0)&(merchant3.coupon_id!=0)][['merchant_id']]\n",
    "t2['sales_use_coupon'] = 1\n",
    "t2 = t2.groupby('merchant_id').agg('sum').reset_index()\n",
    "#显示了商品的优惠券的总数量\n",
    "t3 = merchant3[merchant3.coupon_id != 0][['merchant_id']]\n",
    "t3 ['total_coupon'] = 1\n",
    "t3 = t3.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "#显示商品销量和距离的关系\n",
    "t4 = merchant3[(merchant3.date != 0)&(merchant3.coupon_id != 0)][['merchant_id','distance']]\n",
    "#把数据中的null值全部替换为-1\n",
    "t4.replace('null',-1,inplace=True)\n",
    "t4.distance=t4.distance.fillna(1)\n",
    "t4.distance = t4.distance.astype('int')\n",
    "#再把数据中的-1全部替换为NaN\n",
    "t4.replace(-1,np.nan,inplace=True)\n",
    "#返回用户离商品的距离最小值\n",
    "t5 = t4.groupby('merchant_id').agg('min').reset_index()\n",
    "t5.rename(columns={'distance':'merchant_min_distance'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回用户离商品的距离最大值\n",
    "t6 = t4.groupby('merchant_id').agg('max').reset_index()\n",
    "t6.rename(columns={'distance':'merchant_max_distance'},inplace = True)\n",
    "#print(t6)\n",
    "#返回距离的平均值\n",
    "t7 = t4.groupby('merchant_id').agg('mean').reset_index()\n",
    "t7.rename(columns = {'distance':'merchant_mean_distance'},inplace= True)\n",
    "#返回距离的中位值\n",
    "t8 = t4.groupby('merchant_id').agg('median').reset_index()\n",
    "t8.rename(columns={'distance':'merchant_median_distance'},inplace = True)\n",
    "merchant3_feature = pd.merge(t,t1,on='merchant_id',how='left')\n",
    "#print(merchant3_feature)\n",
    "merchant3_feature = pd.merge(merchant3_feature,t2,on='merchant_id',how='left')\n",
    "#print(merchant3_feature)\n",
    "merchant3_feature = pd.merge(merchant3_feature,t3,on='merchant_id',how='left')\n",
    "#print(merchant3_feature)\n",
    "merchant3_feature = pd.merge(merchant3_feature,t5,on='merchant_id',how='left')\n",
    "#print(merchant3_feature)\n",
    "merchant3_feature = pd.merge(merchant3_feature,t6,on='merchant_id',how='left')\n",
    "#print(merchant3_feature)\n",
    "merchant3_feature = pd.merge(merchant3_feature,t7,on='merchant_id',how='left')\n",
    "#print(merchant3_feature)\n",
    "merchant3_feature = pd.merge(merchant3_feature,t8,on='merchant_id',how='left')\n",
    "#print(merchant3_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据中的NaN用0来替换\n",
    "merchant3_feature.sales_use_coupon = merchant3_feature.sales_use_coupon.replace(np.nan,0)\n",
    "#即优惠券的使用率\n",
    "merchant3_feature['merchant_coupon_transfer_rate'] = merchant3_feature.sales_use_coupon.astype('float')/merchant3_feature.total_coupon\n",
    "#即卖出商品中使用优惠券的占比\n",
    "merchant3_feature['coupon_rate'] = merchant3_feature.sales_use_coupon.astype('float') / merchant3_feature.total_sales\n",
    "#将数据中的NaN用0来替换\n",
    "merchant3_feature.total_coupon = merchant3_feature.total_coupon.replace(np.nan,0)\n",
    "merchant3_feature.to_csv('C:\\data\\merchant3_feature.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#4.user_merchant:\n",
    "      #times_user_buy_merchant_before. \n",
    "\n",
    "all_user_merchant = feature3[['user_id','merchant_id']]\n",
    "all_user_merchant.drop_duplicates(inplace=True)\n",
    "#只保留销售了商品的商户id\n",
    "t = feature3[['user_id','merchant_id','date']]\n",
    "t = t[t.date!=0][['user_id','merchant_id']]\n",
    "#用户一共买了这家商户的多少商品\n",
    "t['user_merchant_buy_total'] = 1\n",
    "t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = feature3[['user_id','merchant_id','coupon_id']]\n",
    "t1 = t1[t1.coupon_id!=0][['user_id','merchant_id']]\n",
    "#用户一共收到一个商户的多少优惠券\n",
    "t1['user_merchant_received'] = 1\n",
    "t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t1.drop_duplicates(inplace = True)\n",
    "\n",
    "\n",
    "t2 = feature3[['user_id','merchant_id','date','date_received']]\n",
    "t2 = t2[(t2.date!=0)&(t2.date_received!=0)][['user_id','merchant_id']]\n",
    "\n",
    "#用户在一家商户中使用优惠券购买的商品的数目\n",
    "t2['user_merchant_buy_use_coupon'] = 1\n",
    "t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t2.drop_duplicates(inplace = True)\n",
    "\n",
    "#用户在一家商家的所有记录总数\n",
    "t3 = feature3[['user_id','merchant_id']]\n",
    "t3['user_merchant_any'] = 1\n",
    "t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t3.drop_duplicates(inplace = True)\n",
    "\n",
    "t4 = feature3[['user_id','merchant_id','date','coupon_id']]\n",
    "t4 = t4[(t4.date!=0)&(t4.coupon_id==0)][['user_id','merchant_id']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用户没有使用优惠券购买的商品的数目\n",
    "t4['user_merchant_buy_common'] = 1\n",
    "t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace = True)\n",
    "\n",
    "user_merchant3 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t1,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t2,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t3,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t4,on=['user_id','merchant_id'],how='left')\n",
    "#都是针对一家商户和一个用户\n",
    "user_merchant3.user_merchant_buy_use_coupon = user_merchant3.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "user_merchant3.user_merchant_buy_common = user_merchant3.user_merchant_buy_common.replace(np.nan,0)\n",
    "#y优惠券的转换率，用户使用了的优惠券/一共收到的优惠券\n",
    "user_merchant3['user_merchant_coupon_transfer_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / user_merchant3.user_merchant_received.astype('float')\n",
    "#用户使用优惠券的概率，在一家商户使用优惠券购买的商品/在一家商户购买商品的总数\n",
    "user_merchant3['user_merchant_coupon_buy_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / user_merchant3.user_merchant_buy_total.astype('float')\n",
    "#用户在商户消费的概率 用户在商户购买的总数/在一家商户浏览的总次数\n",
    "user_merchant3['user_merchant_rate'] = user_merchant3.user_merchant_buy_total.astype('float') / user_merchant3.user_merchant_any.astype('float')\n",
    "#用户在一家商户不适用优惠券购买的概率 普通购买的商品数/购买商品的总数\n",
    "user_merchant3['user_merchant_common_buy_rate'] = user_merchant3.user_merchant_buy_common.astype('float') / user_merchant3.user_merchant_buy_total.astype('float')\n",
    "user_merchant3.to_csv('C:/data/user_merchant3.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#对于数据集2\n",
    "all_user_merchant = feature2[['user_id','merchant_id']]\n",
    "all_user_merchant.drop_duplicates(inplace=True)\n",
    "t = feature2[['user_id','merchant_id','date']]\n",
    "t = t[t.date!=0][['user_id','merchant_id']]\n",
    "t['user_merchant_buy_total'] = 1\n",
    "t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t.drop_duplicates(inplace = True)\n",
    "t1 = feature2[['user_id','merchant_id','coupon_id']]\n",
    "t1 = t1[t1.coupon_id != 0][['user_id','merchant_id']]\n",
    "t1['user_merchant_received'] = 1\n",
    "t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t1.drop_duplicates(inplace = True)\n",
    "t2 = feature2[['user_id','merchant_id','date','date_received']]\n",
    "t2 = t2[(t2.date!=0)&(t2.date_received !=0)][['user_id','merchant_id']]\n",
    "t2['user_merchant_buy_use_coupon'] = 1\n",
    "t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t2.drop_duplicates(inplace= True)\n",
    "t3 = feature2[['user_id','merchant_id']]\n",
    "t3['user_merchant_any'] = 1\n",
    "t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t3.drop_duplicates(inplace=True)\n",
    "t4 = feature2[['user_id','merchant_id','date','coupon_id']]\n",
    "t4 = t4[(t4.date !=0)&(t4.coupon_id == 0)][['user_id','merchant_id']]\n",
    "t4['user_merchant_buy_common'] = 1\n",
    "t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)\n",
    "\n",
    "user_merchant2 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t1,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t2,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t3,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t4,on=['user_id','merchant_id'],how='left')\n",
    "\n",
    "user_merchant2.user_merchant_buy_use_coupon = user_merchant2.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "user_merchant2.user_merchant_buy_common = user_merchant2.user_merchant_buy_common.replace(np.nan,0)\n",
    "\n",
    "user_merchant2['user_merchant_coupon_transfer_rate'] = user_merchant2.user_merchant_buy_use_coupon.astype('float') / user_merchant2.user_merchant_received.astype('float')\n",
    "user_merchant2['user_merchant_coupon_buy_rate'] = user_merchant2.user_merchant_buy_use_coupon.astype('float') / user_merchant2.user_merchant_buy_total.astype('float')\n",
    "user_merchant2['user_merchant_rate'] = user_merchant2.user_merchant_buy_total.astype('float') / user_merchant2.user_merchant_any.astype('float')\n",
    "user_merchant2['user_merchant_common_buy_rate'] = user_merchant2.user_merchant_buy_common.astype('float') / user_merchant2.user_merchant_buy_total.astype('float')\n",
    "user_merchant2.to_csv('C:\\data\\\\user_merchant2.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#for dataset2\n",
    "all_user_merchant = feature1[['user_id','merchant_id']]\n",
    "all_user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "t = feature1[['user_id','merchant_id','date']]\n",
    "t = t[t.date!=0][['user_id','merchant_id']]\n",
    "t['user_merchant_buy_total'] = 1\n",
    "t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = feature1[['user_id','merchant_id','coupon_id']]\n",
    "t1 = t1[t1.coupon_id!=0][['user_id','merchant_id']]\n",
    "t1['user_merchant_received'] = 1\n",
    "t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t1.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = feature1[['user_id','merchant_id','date','date_received']]\n",
    "t2 = t2[(t2.date!=0)&(t2.date_received!=0)][['user_id','merchant_id']]\n",
    "t2['user_merchant_buy_use_coupon'] = 1\n",
    "t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t2.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "t3 = feature1[['user_id','merchant_id']]\n",
    "t3['user_merchant_any'] = 1\n",
    "t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t3.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = feature1[['user_id','merchant_id','date','coupon_id']]\n",
    "t4 = t4[(t4.date!=0)&(t4.coupon_id==0)][['user_id','merchant_id']]\n",
    "t4['user_merchant_buy_common'] = 1\n",
    "t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_merchant1 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t1,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t2,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t3,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t4,on=['user_id','merchant_id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_merchant1.user_merchant_buy_use_coupon = user_merchant1.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "user_merchant1.user_merchant_buy_common = user_merchant1.user_merchant_buy_common.replace(np.nan,0)\n",
    "user_merchant1['user_merchant_coupon_transfer_rate'] = user_merchant1.user_merchant_buy_use_coupon.astype('float') / user_merchant1.user_merchant_received.astype('float')\n",
    "user_merchant1['user_merchant_coupon_buy_rate'] = user_merchant1.user_merchant_buy_use_coupon.astype('float') / user_merchant1.user_merchant_buy_total.astype('float')\n",
    "user_merchant1['user_merchant_rate'] = user_merchant1.user_merchant_buy_total.astype('float') / user_merchant1.user_merchant_any.astype('float')\n",
    "user_merchant1['user_merchant_common_buy_rate'] = user_merchant1.user_merchant_buy_common.astype('float') / user_merchant1.user_merchant_buy_total.astype('float')\n",
    "user_merchant1.to_csv('C:\\data\\\\user_merchant1.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#构建衍生特征\n",
    "############# user related feature   #############\n",
    "\"\"\"\n",
    "3.user related: \n",
    "      count_merchant. \n",
    "      user_avg_distance, user_min_distance,user_max_distance. \n",
    "      buy_use_coupon. buy_total. coupon_received.\n",
    "      buy_use_coupon/coupon_received. \n",
    "      buy_use_coupon/buy_total\n",
    "      user_date_datereceived_gap\n",
    "      \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_user_date_datereceived_gap(s):\n",
    "    s = s.split(':')\n",
    "    return (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8])) - date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days\n",
    "\n",
    "#for dataset3\n",
    "user3 = feature3[['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']]\n",
    "\n",
    "t = user3[['user_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t = user3[['user_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = user3[user3.date!=0][['user_id','merchant_id']]\n",
    "t1.drop_duplicates(inplace=True)\n",
    "t1.merchant_id = 1\n",
    "t1 = t1.groupby('user_id').agg('sum').reset_index()\n",
    "t1.rename(columns={'merchant_id':'count_merchant'},inplace=True)\n",
    "\n",
    "t2 = user3[(user3.date!=0)&(user3.coupon_id!=0)][['user_id','distance']]\n",
    "t2.replace('null',-1,inplace=True)\n",
    "t2.distance = t2.distance.fillna(0)\n",
    "t2.distance = t2.distance.astype('int')\n",
    "t2.replace(-1,np.nan,inplace=True)\n",
    "t3 = t2.groupby('user_id').agg('min').reset_index()\n",
    "t3.rename(columns={'distance':'user_min_distance'},inplace=True)\n",
    "\n",
    "\n",
    "t4 = t2.groupby('user_id').agg('max').reset_index()\n",
    "t4.rename(columns={'distance':'user_max_distance'},inplace=True)\n",
    "\n",
    "t5 = t2.groupby('user_id').agg('mean').reset_index()\n",
    "t5.rename(columns={'distance':'user_mean_distance'},inplace=True)\n",
    "\n",
    "t6 = t2.groupby('user_id').agg('median').reset_index()\n",
    "t6.rename(columns={'distance':'user_median_distance'},inplace=True)\n",
    "\n",
    "t7 = user3[(user3.date!=0)&(user3.coupon_id!=0)][['user_id']]\n",
    "t7['buy_use_coupon'] = 1\n",
    "t7 = t7.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "\n",
    "t8 = user3[user3.date!=0][['user_id']]\n",
    "t8['buy_total'] = 1\n",
    "t8 = t8.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t9 = user3[user3.coupon_id!=0][['user_id']]\n",
    "t9['coupon_received'] = 1\n",
    "t9 = t9.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t10 = user3[(user3.date_received!=0)&(user3.date!=0)][['user_id','date_received','date']]\n",
    "t10.date=t10.date.astype(str)\n",
    "t10.date_received=t10.date.astype(str)\n",
    "t10['user_date_datereceived_gap']=t10.apply(lambda x: x['date']+ ':'+ x['date'],axis=1)\n",
    "t10['user_date_datereceived_gap'].head()\n",
    "t10.user_date_datereceived_gap = t10.user_date_datereceived_gap.apply(get_user_date_datereceived_gap)\n",
    "\n",
    "t10 = t10[['user_id','user_date_datereceived_gap']]\n",
    "\n",
    "t11 = t10.groupby('user_id').agg('mean').reset_index()\n",
    "t11.rename(columns={'user_date_datereceived_gap':'avg_user_date_datereceived_gap'},inplace=True)\n",
    "t12 = t10.groupby('user_id').agg('min').reset_index()\n",
    "t12.rename(columns={'user_date_datereceived_gap':'min_user_date_datereceived_gap'},inplace=True)\n",
    "t13 = t10.groupby('user_id').agg('max').reset_index()\n",
    "t13.rename(columns={'user_date_datereceived_gap':'max_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "user3_feature = pd.merge(t,t1,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t3,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t4,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t5,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t6,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t7,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t8,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t9,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t11,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t12,on='user_id',how='left')\n",
    "user3_feature = pd.merge(user3_feature,t13,on='user_id',how='left')\n",
    "user3_feature.count_merchant = user3_feature.count_merchant.replace(np.nan,0)\n",
    "user3_feature.buy_use_coupon = user3_feature.buy_use_coupon.replace(np.nan,0)\n",
    "user3_feature['buy_use_coupon_rate'] = user3_feature.buy_use_coupon.astype('float') / user3_feature.buy_total.astype('float')\n",
    "user3_feature['user_coupon_transfer_rate'] = user3_feature.buy_use_coupon.astype('float') / user3_feature.coupon_received.astype('float')\n",
    "user3_feature.buy_total = user3_feature.buy_total.replace(np.nan,0)\n",
    "user3_feature.coupon_received = user3_feature.coupon_received.replace(np.nan,0)\n",
    "user3_feature.to_csv('C:/data/user3_feature.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-bc81d25f5255>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoupon_id\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'distance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'null'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mt3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   4995\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4996\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[1;32m-> 4997\u001b[1;33m                                          **kwargs)\n\u001b[0m\u001b[0;32m   4998\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   3712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3713\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3714\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3716\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   3579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3580\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3581\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3582\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[1;32m--> 575\u001b[1;33m                             **kwargs)\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, errors, values, klass, mgr, **kwargs)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             raise ValueError('Cannot convert non-finite values (NA or inf) to '\n\u001b[0m\u001b[0;32m    703\u001b[0m                              'integer')\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "#for dataset2\n",
    "user2 = feature2[['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']]\n",
    "\n",
    "t = user2[['user_id']]\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = user2[user2.date!=0][['user_id','merchant_id']]\n",
    "t1.drop_duplicates(inplace=True)\n",
    "t1.merchant_id = 1\n",
    "t1 = t1.groupby('user_id').agg('sum').reset_index()\n",
    "t1.rename(columns={'merchant_id':'count_merchant'},inplace=True)\n",
    "\n",
    "t2 = user2[(user2.date!=0)&(user2.coupon_id!=0)][['user_id','distance']]\n",
    "t2.replace('null',-1,inplace=True)\n",
    "t2.distance = t2.distance.astype('int')\n",
    "t2.replace(-1,np.nan,inplace=True)\n",
    "t3 = t2.groupby('user_id').agg('min').reset_index()\n",
    "t3.rename(columns={'distance':'user_min_distance'},inplace=True)\n",
    "\n",
    "t4 = t2.groupby('user_id').agg('max').reset_index()\n",
    "t4.rename(columns={'distance':'user_max_distance'},inplace=True)\n",
    "\n",
    "t5 = t2.groupby('user_id').agg('mean').reset_index()\n",
    "t5.rename(columns={'distance':'user_mean_distance'},inplace=True)\n",
    "\n",
    "t6 = t2.groupby('user_id').agg('median').reset_index()\n",
    "t6.rename(columns={'distance':'user_median_distance'},inplace=True)\n",
    "\n",
    "t7 = user2[(user2.date!='null')&(user2.coupon_id!='null')][['user_id']]\n",
    "t7['buy_use_coupon'] = 1\n",
    "t7 = t7.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t8 = user2[user2.date!='null'][['user_id']]\n",
    "t8['buy_total'] = 1\n",
    "t8 = t8.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t9 = user2[user2.coupon_id!='null'][['user_id']]\n",
    "t9['coupon_received'] = 1\n",
    "t9 = t9.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "t10 = user2[(user2.date_received!='null')&(user2.date!='null')][['user_id','date_received','date']]\n",
    "t10['user_date_datereceived_gap'] = t10.date + ':' + t10.date_received\n",
    "t10.user_date_datereceived_gap = t10.user_date_datereceived_gap.apply(get_user_date_datereceived_gap)\n",
    "t10 = t10[['user_id','user_date_datereceived_gap']]\n",
    "\n",
    "t11 = t10.groupby('user_id').agg('mean').reset_index()\n",
    "t11.rename(columns={'user_date_datereceived_gap':'avg_user_date_datereceived_gap'},inplace=True)\n",
    "t12 = t10.groupby('user_id').agg('min').reset_index()\n",
    "t12.rename(columns={'user_date_datereceived_gap':'min_user_date_datereceived_gap'},inplace=True)\n",
    "t13 = t10.groupby('user_id').agg('max').reset_index()\n",
    "t13.rename(columns={'user_date_datereceived_gap':'max_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "user2_feature = pd.merge(t,t1,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t3,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t4,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t5,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t6,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t7,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t8,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t9,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t11,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t12,on='user_id',how='left')\n",
    "user2_feature = pd.merge(user2_feature,t13,on='user_id',how='left')\n",
    "user2_feature.count_merchant = user2_feature.count_merchant.replace(np.nan,0)\n",
    "user2_feature.buy_use_coupon = user2_feature.buy_use_coupon.replace(np.nan,0)\n",
    "user2_feature['buy_use_coupon_rate'] = user2_feature.buy_use_coupon.astype('float') / user2_feature.buy_total.astype('float')\n",
    "user2_feature['user_coupon_transfer_rate'] = user2_feature.buy_use_coupon.astype('float') / user2_feature.coupon_received.astype('float')\n",
    "user2_feature.buy_total = user2_feature.buy_total.replace(np.nan,0)\n",
    "user2_feature.coupon_received = user2_feature.coupon_received.replace(np.nan,0)\n",
    "user2_feature.to_csv('C:/data/user2_feature.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
